# ML_Module_00

## for executing file
```
python3 <filename>
```

## for checking format
```
pycodestyle <filename>
```

## for modifying format
```
black <filename>
```

## conclusion
1. Why do we concatenate a column of ones to the left of the x vector when we use the linear algebra trick?
2. Why does the loss function square the distances between the data points and their predicted values?
3. What does the loss functionâ€™s output represent?
4. Toward which value do we want the loss function to tend? What would that mean?
5. Do you understand why are matrix multiplications are not commutative?
